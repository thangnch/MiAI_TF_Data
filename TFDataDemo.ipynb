{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFDataDemo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IBMYL76FsHg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXo_3m4FIzA3",
        "outputId": "25588e41-c1f9-4283-8a1f-b210340d0c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/cat_dog\n",
        "!unzip Archive.zip"
      ],
      "metadata": {
        "id": "_8WGR_KvMuRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "# - train\n",
        "#   + dogs\n",
        "#   + cats\n",
        "# - val\n",
        "#   + dogs\n",
        "#   + cats"
      ],
      "metadata": {
        "id": "UYFTbLmYJLur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xay dung model clasify đơn giản\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, Dense\n",
        "\n",
        "def build_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD()\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "model = build_model()"
      ],
      "metadata": {
        "id": "2f87MaVPJY5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dữ liệu để train model\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "data_path = \"/content/drive/MyDrive/cat_dog/\"\n",
        "\n",
        "train_data = datagen.flow_from_directory(data_path + \"train/\",\n",
        "  class_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "val_data = datagen.flow_from_directory(data_path + \"val/\",\n",
        "  class_mode='binary', batch_size=64, target_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzgZc3KVJ3q5",
        "outputId": "3ecc0654-b69a-4a24-abf5-cdeaf30da5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19906 images belonging to 2 classes.\n",
            "Found 5094 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "history = model.fit(train_data, steps_per_epoch=len(train_data),\n",
        "  validation_data=val_data, validation_steps=len(val_data), epochs=1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9BK7231PUBl",
        "outputId": "221c9eb4-6e7e-4fed-9a5c-42c53a15efeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312/312 [==============================] - 156s 461ms/step - loss: 0.6861 - accuracy: 0.5777 - val_loss: 0.6495 - val_accuracy: 0.6078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train bang TF.Data"
      ],
      "metadata": {
        "id": "14Wm1FRoQEZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 0. Lấy danh sách các file ảnh train\n",
        "train_image_path = list(paths.list_images(data_path + \"train\"))\n",
        "# 1. Lấy danh sách các file ảnh để val\n",
        "val_image_path = list(paths.list_images(data_path + \"val\"))\n",
        "# 2. Tạo danh sách các class: dogs và cats\n",
        "classNames = np.array(sorted(os.listdir(data_path + \"train\")))\n",
        "# 3. Build 1 hàm xử lý ảnh\n",
        "def preproces_image(image_path):\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_png(image, channels=3)\n",
        "  image = tf.image.resize(image, (224,224))\n",
        "  image = image / 255.0\n",
        "\n",
        "  label = tf.strings.split(image_path, os.path.sep)[-2]\n",
        "  oneHot = label == classNames\n",
        "  encodedLabel = tf.argmax(oneHot)\n",
        "\n",
        "  return (image, encodedLabel)\n"
      ],
      "metadata": {
        "id": "LwE6DoFuQCtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Dùng TF.Data để tạo pipeline load và xử lý ảnh\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_image_path)\n",
        "train_dataset = (train_dataset\n",
        "                 .map(preproces_image, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "                 .batch(64)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "                 )\n",
        "\n"
      ],
      "metadata": {
        "id": "hz59-2YGRmKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Dùng TF.Data để tạo pipeline load và xử lý ảnh\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_image_path)\n",
        "val_dataset = (val_dataset\n",
        "                 .map(preproces_image, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "                 .batch(64)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "                 )\n",
        "\n"
      ],
      "metadata": {
        "id": "BFaccqd3Qod5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "history = model.fit(train_dataset, steps_per_epoch=len(train_dataset),\n",
        "  validation_data=val_dataset, validation_steps=len(val_dataset), epochs=1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_w1rHqjSnqD",
        "outputId": "b6ff4a4d-8e55-4ef3-ada8-454a20263680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "312/312 [==============================] - 93s 295ms/step - loss: 0.0400 - accuracy: 0.9918 - val_loss: 5.1716 - val_accuracy: 0.4969\n"
          ]
        }
      ]
    }
  ]
}